{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import resize\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from unet import UNet\n",
    "from loss import cross_entropy2d\n",
    "from preprocessing import image_crop\n",
    "from image_handle import analyze_mask_classes, analyze_mask_classes_rgb, image_color_mapping\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from PIL import Image\n",
    "from dp_support import *\n",
    "from path_handle import find_files_with_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = r\".\\image\"\n",
    "train_label_dir = r\".\\mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of .\\image : 6\n",
      "lenth of .\\mask : 6\n"
     ]
    }
   ],
   "source": [
    "train_image_file_name_list,train_image_file_name_list_length = find_files_with_extension(train_image_dir,[\".jpg\"])\n",
    "train_label_file_name_list, train_label_file_name_list_length = find_files_with_extension(train_label_dir, [\".png\"])\n",
    "print(train_image_file_name_list,train_image_file_name_list_length)\n",
    "print(train_label_file_name_list, train_label_file_name_list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# 检查训练数据集图像和标签文件列表长度是否一致\n",
    "if train_image_file_name_list_length == train_label_file_name_list_length:\n",
    "    # 继续执行\n",
    "    pass\n",
    "else:\n",
    "    # 退出并报错\n",
    "    raise ValueError(\"Training image file list length does not match training label file list length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of .\\image : 6\n",
      "lenth of .\\mask : 6\n"
     ]
    }
   ],
   "source": [
    "val_image_dir = r\".\\image\"\n",
    "val_label_dir = r\".\\mask\"\n",
    "\n",
    "# 找到验证数据集图像和标签文件列表\n",
    "val_image_file_name_list, val_image_file_name_list_length = find_files_with_extension(val_image_dir, [\".jpg\"])\n",
    "val_label_file_name_list, val_label_file_name_list_length = find_files_with_extension(val_label_dir, [\".png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 检查验证数据集图像和标签文件列表长度是否一致\n",
    "if val_image_file_name_list_length == val_label_file_name_list_length:\n",
    "    # 继续执行\n",
    "    pass\n",
    "else:\n",
    "    # 退出并报错\n",
    "    raise ValueError(\"Validation image file list length does not match validation label file list length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNDataset(Dataset):\n",
    "    #当你使用DataLoader时，它会自动为你的数据批量添加一个批次维度（batch dimension）?\n",
    "\n",
    "    def __init__(self, image_path_list: list, label_path_list: list, file_list_length: int):\n",
    "        self.transform = transforms.Compose([\n",
    "            # CustomResizeTransform(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        # self.mask_transform = transforms.Compose([\n",
    "        #     # CustomResizeTransform(),\n",
    "        #     transforms.ToTensor(),\n",
    "        # ])\n",
    "        self.image_path_list = image_path_list[0:100]\n",
    "        self.label_path_list = label_path_list[0:100]\n",
    "        self.file_list_length = 100\n",
    "        self.color_map = {0: 0}\n",
    "        self.width = self.height = 224\n",
    "\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        # print(self.label_path_list[i])\n",
    "        image = Image.open(self.image_path_list[i]).convert('RGB')\n",
    "        mask = Image.open(self.label_path_list[i]).convert('L')\n",
    "        \n",
    "        \n",
    "        image_width, image_height = image.size\n",
    "        if image_width < self.width:\n",
    "            if  image_height < self.height:\n",
    "                image = image.resize((self.width, self.height), Image.BILINEAR)\n",
    "                mask = mask.resize((self.width, self.height), Image.NEAREST)\n",
    "            else:\n",
    "                image = image.resize((self.width, image_height), Image.BILINEAR)\n",
    "                mask = mask.resize((self.width, image_height), Image.NEAREST)\n",
    "        else:\n",
    "            if  image_height < self.height:\n",
    "                image = image.resize((image_width, self.height), Image.BILINEAR)\n",
    "                mask = mask.resize((image_width, self.height), Image.NEAREST)\n",
    "            \n",
    "        # image = image.resize((self.width, self.height), Image.NEAREST)\n",
    "        # mask = mask.resize((self.width, self.height), Image.NEAREST)\n",
    "\n",
    "        # print(np.array(image).shape)\n",
    "\n",
    "        # print(analyze_mask_classes(mask))\n",
    "        \n",
    "        mask_np_array, self.color_map = image_color_mapping(np.array(mask), self.color_map)\n",
    "        # for i in mask_np_array.tolist():\n",
    "        #     print(i)\n",
    "        # print(self.color_map)\n",
    "        # expanded_mask = np.expand_dims(mask, axis=2)\n",
    "        \n",
    "      \n",
    "        if self.transform != None: \n",
    "\n",
    "            image = self.transform(image)\n",
    "            mask =  torch.from_numpy(mask_np_array)\n",
    "            # mask = self.mask_transform(mask)\n",
    "        # 将mask从[1, H, W]压缩为[H, W]，去掉单一的通道维度\n",
    "        image, mask = image_crop(image ,mask ,height=self.height , width=self.width)\n",
    "        # mask = torch.squeeze(mask, 0)\n",
    "        mask = mask.squeeze(0).long()\n",
    "        # for i in mask.tolist():\n",
    "        #     print(i)\n",
    " \n",
    "        # numpy_array = mask.numpy()\n",
    "\n",
    "        # # 打印 NumPy 数组\n",
    "        # print(numpy_array)\n",
    "        # plt.imshow(mask, cmap='gray')  # 假设 mask 是灰度图像\n",
    "        # plt.title('Mask')\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "        return image, mask, self.color_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.file_list_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20\n",
    "# print(color_map)\n",
    "train_dataset = FCNDataset(\n",
    "    train_image_file_name_list, \n",
    "    train_label_file_name_list,\n",
    "    file_list_length = train_image_file_name_list_length,\n",
    ")\n",
    "val_dataset = FCNDataset(\n",
    "    val_image_file_name_list, \n",
    "    val_label_file_name_list, \n",
    "    file_list_length = val_image_file_name_list_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            num_workers= num_workers,\n",
    "                            pin_memory=True\n",
    "                            )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            num_workers= num_workers,\n",
    "                            pin_memory=True\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using version: 2.2.1+cu121\n",
      "\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Total memory: 7.99951171875 GB\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m lr, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain_model\u001b[49m(model, device, train_loader, val_loader,optimizer,num_epochs, num_classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "device = pytorch_test()\n",
    "if device != None:\n",
    "    # model = FCN(num_classes, step= 8).to(device)\n",
    "    model = UNet(num_classes).to(device)\n",
    "    lr, num_epochs = 0.001, 1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_model(model, device, train_loader, val_loader,optimizer,num_epochs, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
